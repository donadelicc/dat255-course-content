{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.text.all import *\n",
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastAI applicaiton has this approach:\n",
    "\n",
    "- Create appropriate DataLoaders\n",
    "- Create a Learner\n",
    "- Call a fit method\n",
    "- Make predictions or view results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **DataBlock**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),             # Define data types for the input and output\n",
    "    get_items=get_image_files,                      # Function to get image files\n",
    "    splitter=GrandparentSplitter(train_name='train', \n",
    "                                 valid_name='test'),# Split data based on grandparent folder name\n",
    "    get_y=parent_label,                             # Get labels from parent folder names\n",
    "    item_tfms=Resize(224),                          # Resize images to 224x224\n",
    "    batch_tfms=[\n",
    "        *aug_transforms(),                          # Apply some data augmentation\n",
    "        Normalize.from_stats(*imagenet_stats)       # Normalize image intensities (because pretraining)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up a DataBlock, a versatile FastAI tool for building datasets. It specifies the data types (images and categories), how to retrieve images and labels, and how to split the dataset (80% for training and 20% for validation). The item_tfms and batch_tfms apply transformations such as resizing and data augmentation, which are crucial for improving model robustness and handling varying image sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **DATA LOADER**\n",
    "\n",
    "--> adding functionality to Pytorch's DataLoader class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DataLoader (dataset=None, bs=None, num_workers=0, pin_memory=False,\n",
    "             timeout=0, batch_size=None, shuffle=False, drop_last=False,\n",
    "             indexed=None, n=None, device=None, persistent_workers=False,\n",
    "             pin_memory_device='', wif=None, before_iter=None,\n",
    "             after_item=None, before_batch=None, after_batch=None,\n",
    "             after_iter=None, create_batches=None, create_item=None,\n",
    "             create_batch=None, retain=None, get_idxs=None, sample=None,\n",
    "             shuffle_fn=None, do_batch=None)\n",
    "\n",
    "Aguments:\n",
    "\n",
    "- dataset: dataset from which to load the data. Can be either map-style or iterable-style dataset.\n",
    "- bs (int): how many samples per batch to load (if batch_size is provided then batch_size will override bs). If bs=None, then it is assumed that dataset.__getitem__ returns a batch.\n",
    "- num_workers (int): how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.\n",
    "- pin_memory (bool): If True, the data loader will copy Tensors into CUDA pinned memory before returning them.\n",
    "- timeout (float>0): the timeout value in seconds for collecting a batch from workers.\n",
    "- batch_size (int): It is only provided for PyTorch compatibility. Use bs.\n",
    "- shuffle (bool): If True, then data is shuffled every time dataloader is fully read/iterated.\n",
    "- drop_last (bool): If True, then the last incomplete batch is dropped.\n",
    "- indexed (bool): The DataLoader will make a guess as to whether the dataset can be indexed (or is iterable), but you can override it with this parameter. True by default.\n",
    "- n (int): Defaults to len(dataset). If you are using iterable-style dataset, you can specify the size with n.\n",
    "- device (torch.device): Defaults to default_device() which is CUDA by default. You can specify device as torch.device('cpu')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Block/Loader EXAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Using a DataBlock\n",
    "- When you don't have a prebuilt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='168173568' class='' max='168168549' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [168173568/168168549 00:15&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "\n",
    "# Download and prepare the CIFAR-10 dataset\n",
    "path = untar_data(URLs.CIFAR)\n",
    "\n",
    "data = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),             # Define data types for the input and output\n",
    "    get_items=get_image_files,                      # Function to get image files\n",
    "    splitter=GrandparentSplitter(train_name='train', \n",
    "                                 valid_name='test'),# Split data based on grandparent folder name\n",
    "    get_y=parent_label,                             # Get labels from parent folder names\n",
    "    item_tfms=Resize(224),                          # Resize images to 224x224\n",
    "    batch_tfms=[\n",
    "        *aug_transforms(),                          # Apply some data augmentation (see Chapter 2)\n",
    "        Normalize.from_stats(*imagenet_stats)       # Normalize image intensities (because pretraining)\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = data.dataloaders(path, bs=64)\n",
    "# dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Using .from_folder\n",
    "\n",
    "```\n",
    "(method) def from_folder(\n",
    "    path: Any,\n",
    "    train: str = 'train',\n",
    "    valid: str = 'valid',\n",
    "    valid_pct: Any | None = None,\n",
    "    seed: Any | None = None,\n",
    "    vocab: Any | None = None,\n",
    "    item_tfms: Any | None = None,\n",
    "    batch_tfms: Any | None = None,\n",
    "    img_cls: type[PILImage] = PILImage,\n",
    "    **kwargs: Any\n",
    ") -> Any\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.CIFAR)\n",
    "\n",
    "\n",
    "dls = ImageDataLoaders.from_folder(path, train='train', valid='valid', item_tfms=Resize(224))\n",
    "# dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other types\n",
    "\n",
    "**from_name_func**:\n",
    "- Allows you to create DataLoaders by defining a function that extracts labels from filenames. This method is useful when labels are embedded in the file names themselves.\n",
    "**from_path_func**:\n",
    "- Similar to from_name_func, but the function receives the full path of each file, providing more flexibility for extracting labels based on the file path.\n",
    "**from_df**:\n",
    "- Creates DataLoaders from a pandas DataFrame. This is particularly useful for datasets that come in tabular form where one of the columns might contain file paths or text data, and another column the labels.\n",
    "**from_csv**:\n",
    "- Similar to from_df, but loads data directly from a CSV file. You specify the path to the CSV file and details about which columns to use for the data and labels.\n",
    "**from_lists**:\n",
    "- Allows you to directly pass lists of data points and labels to create DataLoaders. This is handy when you have already pre-processed your data in memory.\n",
    "*from_dblock*:\n",
    "- Creates DataLoaders using a DataBlock, which is a more flexible and customizable way to define how to gather data, split it, and form batches. DataBlock allows you to compose a pipeline for loading and preprocessing the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tabular data loader\n",
    "\n",
    "```\n",
    " TabularDataLoaders (*loaders, path:str|pathlib.Path='.', device=None)\n",
    "```\n",
    "Most used one:\n",
    "```\n",
    "TabularDataLoaders.from_df (df:pd.DataFrame, path:str|Path='.',\n",
    "                             procs:list=None, cat_names:list=None,\n",
    "                             cont_names:list=None, y_names:list=None,\n",
    "                             y_block:TransformBlock=None,\n",
    "                             valid_idx:list=None, bs:int=64,\n",
    "                             shuffle_train:bool=None, shuffle:bool=True,\n",
    "                             val_shuffle:bool=False, n:int=None,\n",
    "                             device:torch.device=None,\n",
    "                             drop_last:bool=None, val_bs:int=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='974848' class='' max='968212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.69% [974848/968212 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "\n",
    "df = pd.read_csv(path/'adult.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num  \\\n",
       "0   49            Private  101320    Assoc-acdm           12.0   \n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race  \\\n",
       "0   Married-civ-spouse               NaN            Wife                White   \n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced               NaN       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country salary  \n",
       "0   Female             0          1902              40   United-States  >=50k  \n",
       "1     Male         10520             0              45   United-States  >=50k  \n",
       "2   Female             0             0              32   United-States   <50k  \n",
       "3     Male             0             0              40   United-States  >=50k  \n",
       "4   Female             0             0              50   United-States   <50k  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prebe\\OneDrive\\HVL2\\DAT255\\Course_content\\venv\\Lib\\site-packages\\fastai\\tabular\\core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessors\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "dep_var = 'salary'\n",
    "cont_vars, cat_vars = cont_cat_split(df, max_card=4000, dep_var=dep_var, )\n",
    "\n",
    "splits = RandomSplitter()(range_of(df))\n",
    "to = TabularPandas(df, procs, cat_vars, cont_vars, y_names=dep_var, splits=splits, y_block=CategoryBlock())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(to.xs.iloc[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data transformation**\n",
    "\n",
    "#### Functions for getting, splitting, and labeling data, as well as generic transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('C:/Users/prebe/.fastai/data/mnist_tiny/train/3'),Path('C:/Users/prebe/.fastai/data/mnist_tiny/train/7')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GET DATA\n",
    "\n",
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```get_files(path)```\n",
    "- Get all files from path\n",
    "\n",
    "``` get_images_files(path) ```\n",
    "- This is simply get_files called with a list of standard image extensions.\n",
    "\n",
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` RandomSplitter (valid_pct=0.2, seed=None)```\n",
    "- Create function that splits items between train/val with valid_pct randomly.\n",
    "\n",
    "```TrainTestSplitter()```\n",
    "- Split items into random train and test subsets using sklearn train_test_split utility.\n",
    "\n",
    "```GrandparentSplitter(train_name=\"train\", valid_name=\"valid\")```\n",
    "- Split items from the grand parent folder names (train_name and valid_name).\n",
    "- Often used with prebuilt datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEARNER\n",
    "##### Groups together a model, data loaders and a loss function to handle training\n",
    "\n",
    "___________________\n",
    "\n",
    "**Model**: \n",
    "This is the actual neural network that you want to train. It can be any PyTorch model.\n",
    "\n",
    "**DataLoaders**: \n",
    "This is the FastAI object that contains your training and validation (and optionally test) data loaders. Each DataLoader provides batches of data to the model during training and validation.\n",
    "\n",
    "**Optimizer**: \n",
    "This is the algorithm used to update the weights of the model based on the gradients of the loss function. Common optimizers include SGD, Adam, etc.\n",
    "\n",
    "**Loss Function**: \n",
    "This is a function that measures the difference between the actual values and predictions, guiding the training process by indicating how well the model is performing.\n",
    "\n",
    "**Metrics**: \n",
    "These are additional functions used to evaluate the performance of the model. Unlike the loss function, metrics are used for human interpretation and are not used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "# Load a sample dataset\n",
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")[:100]\n",
    "\n",
    "def label_func(f): return f[0].isupper()\n",
    "\n",
    "# Prepare DataLoaders\n",
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))\n",
    "\n",
    "# Define a simple model\n",
    "learn = vision_learner(dls, resnet34, metrics=accuracy)\n",
    "\n",
    "# Train the model\n",
    "# learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other learners\n",
    "\n",
    "\n",
    "1. TextLearner\n",
    "- language_model_learner\n",
    "- text_classifier_learner\n",
    "\n",
    "\n",
    "2. TabularLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________\n",
    "##### Text Learner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `n_workers` has to be changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from fastai.text.all import *\n",
    "\n",
    "\n",
    "\n",
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "\n",
    "df = pd.read_csv(path/'texts.csv')\n",
    "\n",
    "dls = TextDataLoaders.from_df(df, path=path, text_col='text', label_col='label', valid_col='is_valid')\n",
    "\n",
    "learn = text_classifier_learner(dls, AWD_LSTM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tabular Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prebe\\OneDrive\\HVL2\\DAT255\\Course_content\\venv\\Lib\\site-packages\\fastai\\tabular\\core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "dls = TabularDataLoaders.from_df(df, path, procs=procs, cat_names=cat_names, cont_names=cont_names, \n",
    "                                 y_names=\"salary\", valid_idx=list(range(800,1000)), bs=64)\n",
    "learn = tabular_learner(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prebe\\OneDrive\\HVL2\\DAT255\\Course_content\\venv\\Lib\\site-packages\\fastai\\tabular\\core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessors\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "dep_var = 'salary'\n",
    "cont_vars, cat_vars = cont_cat_split(df, max_card=4000, dep_var=dep_var, )\n",
    "\n",
    "splits = RandomSplitter()(range_of(df))\n",
    "to = TabularPandas(df, procs, cat_vars, cont_vars, y_names=dep_var, splits=splits, y_block=CategoryBlock())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning.fit()\n",
    "\n",
    " ```Learner.fit (n_epoch, lr=None, wd=None, cbs=None, reset_opt=False, start_epoch=0)```\n",
    "\n",
    " - n_epoch: antall epochs(antall treningssykluser)\n",
    " - lr: learning rate\n",
    " - wd: weight decay\n",
    " - cbs: callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________\n",
    "\n",
    "#### Finding a good learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Learner.lr_find() got an unexpected keyword argument 'num_iterations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuggest_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalley\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslide\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Learner.lr_find() got an unexpected keyword argument 'num_iterations'"
     ]
    }
   ],
   "source": [
    "learning_rate = learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
